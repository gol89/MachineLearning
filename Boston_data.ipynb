{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = boston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features,target,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinerRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = regression.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.51744423117726"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1627098714574124"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.64896005, 36.49501384, 15.4111932 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.6, 32.4, 13.6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.63108403569348"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.33470103e-01,  3.58089136e-02,  4.95226452e-02,  3.11983512e+00,\n",
       "       -1.54170609e+01,  4.05719923e+00, -1.08208352e-02, -1.38599824e+00,\n",
       "        2.42727340e-01, -8.70223437e-03, -9.10685208e-01,  1.17941159e-02,\n",
       "       -5.47113313e-01])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus our model is off by around 3-4K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us capture the dependence among the features using PolynomialFeatures and try to predict the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = PolynomialFeatures(degree=3,include_bias=False,interaction_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_interaction = interaction.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.98500000e-02, 0.00000000e+00, 2.18000000e+00, 0.00000000e+00,\n",
       "       4.58000000e-01, 6.43000000e+00, 5.87000000e+01, 6.06220000e+00,\n",
       "       3.00000000e+00, 2.22000000e+02, 1.87000000e+01, 3.94120000e+02,\n",
       "       5.21000000e+00, 8.91022500e-04, 0.00000000e+00, 6.50730000e-02,\n",
       "       0.00000000e+00, 1.36713000e-02, 1.91935500e-01, 1.75219500e+00,\n",
       "       1.80956670e-01, 8.95500000e-02, 6.62670000e+00, 5.58195000e-01,\n",
       "       1.17644820e+01, 1.55518500e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.75240000e+00, 0.00000000e+00,\n",
       "       9.98440000e-01, 1.40174000e+01, 1.27966000e+02, 1.32155960e+01,\n",
       "       6.54000000e+00, 4.83960000e+02, 4.07660000e+01, 8.59181600e+02,\n",
       "       1.13578000e+01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.09764000e-01,\n",
       "       2.94494000e+00, 2.68846000e+01, 2.77648760e+00, 1.37400000e+00,\n",
       "       1.01676000e+02, 8.56460000e+00, 1.80506960e+02, 2.38618000e+00,\n",
       "       4.13449000e+01, 3.77441000e+02, 3.89799460e+01, 1.92900000e+01,\n",
       "       1.42746000e+03, 1.20241000e+02, 2.53419160e+03, 3.35003000e+01,\n",
       "       3.44569000e+03, 3.55851140e+02, 1.76100000e+02, 1.30314000e+04,\n",
       "       1.09769000e+03, 2.31348440e+04, 3.05827000e+02, 3.67502688e+01,\n",
       "       1.81866000e+01, 1.34580840e+03, 1.13363140e+02, 2.38923426e+03,\n",
       "       3.15840620e+01, 9.00000000e+00, 6.66000000e+02, 5.61000000e+01,\n",
       "       1.18236000e+03, 1.56300000e+01, 4.92840000e+04, 4.15140000e+03,\n",
       "       8.74946400e+04, 1.15662000e+03, 3.49690000e+02, 7.37004400e+03,\n",
       "       9.74270000e+01, 1.55330574e+05, 2.05336520e+03, 2.71441000e+01,\n",
       "       2.65970216e-05, 0.00000000e+00, 1.94242905e-03, 0.00000000e+00,\n",
       "       4.08088305e-04, 5.72927468e-03, 5.23030208e-02, 5.40155660e-03,\n",
       "       2.67306750e-03, 1.97806995e-01, 1.66621208e-02, 3.51169788e-01,\n",
       "       4.64222723e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.41859140e-01, 0.00000000e+00, 2.98034340e-02,\n",
       "       4.18419390e-01, 3.81978510e+00, 3.94485541e-01, 1.95219000e-01,\n",
       "       1.44462060e+01, 1.21686510e+00, 2.56465708e+01, 3.39030330e-01,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 6.26145540e-03, 8.79064590e-02,\n",
       "       8.02505310e-01, 8.28781549e-02, 4.10139000e-02, 3.03502860e+00,\n",
       "       2.55653310e-01, 5.38813276e+00, 7.12274730e-02, 1.23414526e+00,\n",
       "       1.12666139e+01, 1.16355139e+00, 5.75806500e-01, 4.26096810e+01,\n",
       "       3.58919385e+00, 7.56456193e+01, 9.99983955e-01, 1.02853847e+02,\n",
       "       1.06221565e+01, 5.25658500e+00, 3.88987290e+02, 3.27660465e+01,\n",
       "       6.90575093e+02, 9.12893595e+00, 1.09699552e+00, 5.42870010e-01,\n",
       "       4.01723807e+01, 3.38388973e+00, 7.13186428e+01, 9.42784251e-01,\n",
       "       2.68650000e-01, 1.98801000e+01, 1.67458500e+00, 3.52934460e+01,\n",
       "       4.66555500e-01, 1.47112740e+03, 1.23919290e+02, 2.61171500e+03,\n",
       "       3.45251070e+01, 1.04382465e+01, 2.19995813e+02, 2.90819595e+00,\n",
       "       4.63661765e+03, 6.12929512e+01, 8.10251385e-01, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 1.03602320e+01, 0.00000000e+00, 2.17659920e+00,\n",
       "       3.05579320e+01, 2.78965880e+02, 2.88099993e+01, 1.42572000e+01,\n",
       "       1.05503280e+03, 8.88698800e+01, 1.87301589e+03, 2.47600040e+01,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 4.57285520e-01, 6.41996920e+00,\n",
       "       5.86084280e+01, 6.05274297e+00, 2.99532000e+00, 2.21653680e+02,\n",
       "       1.86708280e+01, 3.93505173e+02, 5.20187240e+00, 9.01318820e+01,\n",
       "       8.22821380e+02, 8.49762823e+01, 4.20522000e+01, 3.11186280e+03,\n",
       "       2.62125380e+02, 5.52453769e+03, 7.30306540e+01, 7.51160420e+03,\n",
       "       7.75755485e+02, 3.83898000e+02, 2.84084520e+04, 2.39296420e+03,\n",
       "       5.04339599e+04, 6.66702860e+02, 8.01155861e+01, 3.96467880e+01,\n",
       "       2.93386231e+03, 2.47131645e+02, 5.20853070e+03, 6.88532552e+01,\n",
       "       1.96200000e+01, 1.45188000e+03, 1.22298000e+02, 2.57754480e+03,\n",
       "       3.40734000e+01, 1.07439120e+05, 9.05005200e+03, 1.90738315e+05,\n",
       "       2.52143160e+03, 7.62324200e+02, 1.60666959e+04, 2.12390860e+02,\n",
       "       3.38620652e+05, 4.47633614e+03, 5.91741380e+01, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.60719120e-02, 1.34878252e+00,\n",
       "       1.23131468e+01, 1.27163132e+00, 6.29292000e-01, 4.65676080e+01,\n",
       "       3.92258680e+00, 8.26721877e+01, 1.09287044e+00, 1.89359642e+01,\n",
       "       1.72867978e+02, 1.78528153e+01, 8.83482000e+00, 6.53776680e+02,\n",
       "       5.50703780e+01, 1.16065975e+03, 1.53431374e+01, 1.57812602e+03,\n",
       "       1.62979822e+02, 8.06538000e+01, 5.96838120e+03, 5.02742020e+02,\n",
       "       1.05957586e+04, 1.40068766e+02, 1.68316231e+01, 8.32946280e+00,\n",
       "       6.16380247e+02, 5.19203181e+01, 1.09426929e+03, 1.44655004e+01,\n",
       "       4.12200000e+00, 3.05028000e+02, 2.56938000e+01, 5.41520880e+02,\n",
       "       7.15854000e+00, 2.25720720e+04, 1.90134120e+03, 4.00725451e+04,\n",
       "       5.29731960e+02, 1.60158020e+02, 3.37548015e+03, 4.46215660e+01,\n",
       "       7.11414031e+04, 9.40441262e+02, 1.24319978e+01, 2.65847707e+02,\n",
       "       2.42694563e+03, 2.50641053e+02, 1.24034700e+02, 9.17856780e+03,\n",
       "       7.73149630e+02, 1.62948520e+04, 2.15406929e+02, 2.21557867e+04,\n",
       "       2.28812283e+03, 1.13232300e+03, 8.37919020e+04, 7.05814670e+03,\n",
       "       1.48757047e+05, 1.96646761e+03, 2.36304229e+02, 1.16939838e+02,\n",
       "       8.65354801e+03, 7.28924990e+02, 1.53627763e+04, 2.03085519e+02,\n",
       "       5.78700000e+01, 4.28238000e+03, 3.60723000e+02, 7.60257480e+03,\n",
       "       1.00500900e+02, 3.16896120e+05, 2.66935020e+04, 5.62590535e+05,\n",
       "       7.43706660e+03, 2.24850670e+03, 4.73893829e+04, 6.26455610e+02,\n",
       "       9.98775593e+05, 1.32031382e+04, 1.74536563e+02, 2.02262003e+05,\n",
       "       2.08884619e+04, 1.03370700e+04, 7.64943180e+05, 6.44344030e+04,\n",
       "       1.35801534e+06, 1.79520449e+04, 2.15724078e+03, 1.06755342e+03,\n",
       "       7.89989531e+04, 6.65441632e+03, 1.40248051e+05, 1.85398444e+03,\n",
       "       5.28300000e+02, 3.90942000e+04, 3.29307000e+03, 6.94045320e+04,\n",
       "       9.17481000e+02, 2.89297080e+06, 2.43687180e+05, 5.13593537e+06,\n",
       "       6.78935940e+04, 2.05268030e+04, 4.32621583e+05, 5.71896490e+03,\n",
       "       9.11790472e+06, 1.20532537e+05, 1.59335867e+03, 2.22787480e+02,\n",
       "       1.10250807e+02, 8.15855968e+03, 6.87230027e+02, 1.44840160e+04,\n",
       "       1.91468901e+02, 5.45598000e+01, 4.03742520e+03, 3.40089420e+02,\n",
       "       7.16770279e+03, 9.47521860e+01, 2.98769465e+05, 2.51666171e+04,\n",
       "       5.30410007e+05, 7.01166176e+03, 2.11989072e+03, 4.46786807e+04,\n",
       "       5.90621959e+02, 9.41645008e+05, 1.24479105e+04, 1.64552963e+02,\n",
       "       2.70000000e+01, 1.99800000e+03, 1.68300000e+02, 3.54708000e+03,\n",
       "       4.68900000e+01, 1.47852000e+05, 1.24542000e+04, 2.62483920e+05,\n",
       "       3.46986000e+03, 1.04907000e+03, 2.21101320e+04, 2.92281000e+02,\n",
       "       4.65991723e+05, 6.16009560e+03, 8.14323000e+01, 1.09410480e+07,\n",
       "       9.21610800e+05, 1.94238101e+07, 2.56769640e+05, 7.76311800e+04,\n",
       "       1.63614977e+06, 2.16287940e+04, 3.44833875e+07, 4.55847074e+05,\n",
       "       6.02599020e+03, 6.53920300e+03, 1.37819823e+05, 1.82188490e+03,\n",
       "       2.90468174e+06, 3.83979292e+04, 5.07594670e+02, 6.12188860e+07,\n",
       "       8.09272293e+05, 1.06980327e+04, 1.41420761e+02])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_interaction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 559)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_interaction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = regression.fit(features_interaction,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-648.4222282980659"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.12447637e-04, -4.14260594e-02, -5.49236418e-03, -4.42288374e-05,\n",
       "        2.00131071e-03,  2.52982698e-02,  1.57345504e-01, -9.27168827e-03,\n",
       "        1.87870264e-02,  1.25102336e-02,  3.13229796e-05, -2.51115310e-03,\n",
       "       -5.58204630e-02,  2.15986146e-02,  2.55911802e-02, -1.47508178e-02,\n",
       "        2.20540405e-03, -2.59194314e-03,  9.03262164e-03,  6.89707576e-01,\n",
       "       -9.78554621e-02,  1.64136113e-02,  1.17262947e-01, -1.36026620e-03,\n",
       "       -5.66158685e-02,  1.20787593e-01, -2.20743449e-01, -1.48165606e-01,\n",
       "       -1.25634669e-03,  1.43706201e-03, -4.48435094e-01, -7.15858902e-01,\n",
       "       -7.93785742e-01, -4.54371016e-01,  3.84152901e-02,  5.88575782e-01,\n",
       "        1.30655877e-01, -9.76868748e-01, -3.77318941e-02,  1.02172637e-03,\n",
       "        1.99470199e-04, -1.17668477e-01, -6.13825786e-01, -6.12679363e-02,\n",
       "       -5.15511929e-04,  1.83781411e-01, -1.42558434e-01, -6.46271922e-02,\n",
       "        2.31439564e-01, -4.42193422e-05, -6.13428186e-04,  9.07857996e-04,\n",
       "        3.29549567e-03, -6.96682440e-04,  2.64046283e-03,  3.97004684e-02,\n",
       "        2.99271352e-04, -1.34470151e-02, -5.90077084e-03,  2.09734255e-03,\n",
       "        1.70341367e-02,  1.83820044e-01,  4.71277432e-03,  2.16014363e-02,\n",
       "        3.76964946e-01,  1.75516289e-02,  3.71511380e-01,  5.64413657e-02,\n",
       "        3.06957366e-01, -1.00453205e+00,  1.57219301e-01, -1.77208787e-02,\n",
       "       -3.78280364e-01,  3.63505051e-01,  1.02764387e+00, -3.06577153e-01,\n",
       "       -1.84219071e-01,  9.88489590e-01,  4.36642413e-01,  6.22510696e-02,\n",
       "        8.56521238e-01, -2.77082263e-02,  3.80085826e-01, -1.28237800e-01,\n",
       "        8.78211627e-02,  1.86292604e-01, -6.27819773e-02, -7.20009490e-01,\n",
       "       -3.42358220e-02, -5.76604086e-02,  5.63229541e-01,  2.05061498e-01,\n",
       "        2.44515337e-01,  4.51530902e-01, -3.53950939e-02,  1.76119019e-01,\n",
       "        1.20854175e-02,  1.18330275e-01, -1.35324215e-01,  7.70329086e-02,\n",
       "       -7.02376780e-01, -3.78721980e-03, -1.95073629e-01,  8.37816403e-01,\n",
       "        1.88932061e-04, -1.12177882e-01,  3.33077461e-01,  1.19580436e-02,\n",
       "        1.27671850e+00, -4.29647668e-02, -1.98004700e-02, -1.26761974e-01,\n",
       "       -3.46693474e-01,  1.90021453e-03,  8.22503882e-02,  1.29474438e-03,\n",
       "        1.49129694e-02,  1.04326890e-01,  1.04009592e+00,  9.18808425e-03,\n",
       "        3.29452990e-02, -1.15397404e+00,  1.48545607e-02, -1.84767868e+00,\n",
       "       -2.72004726e-01,  5.58633885e-02,  5.44741496e-01, -4.40372371e-02,\n",
       "        9.56932640e-03,  7.24282316e-01,  4.40890280e-02, -1.20314951e-01,\n",
       "        1.14165604e+00,  4.71937850e-02, -2.57239788e-01, -1.19508729e-01,\n",
       "        2.53555476e-02, -2.61669898e-01, -7.95193311e-02, -6.88971199e-02,\n",
       "        2.20540667e-03, -3.65167650e-04, -1.01913768e-02,  3.16304682e-02,\n",
       "       -1.68995041e-02, -4.64276609e-02,  7.03178028e-02,  1.56874735e-02,\n",
       "       -1.33205266e-01,  1.29899252e-04, -9.78403471e-02, -3.55363478e-02,\n",
       "       -1.38751013e+00, -1.16176011e-01,  1.07564823e-01,  7.30577627e-02,\n",
       "       -2.89691637e-03,  2.19153929e-01, -2.16007945e+00, -7.55163044e-01,\n",
       "       -1.13837786e-01, -5.43551671e-01, -8.18833506e-01,  3.01015403e-02,\n",
       "        3.68279454e-01, -2.40766970e-02,  1.10409580e-01,  1.40640777e-03,\n",
       "       -1.42013336e-01, -2.81175549e-01,  1.67606281e-02, -1.64141533e-01,\n",
       "       -1.57154225e-03,  1.35399841e-03, -9.00940218e-01,  5.09191557e-01,\n",
       "        3.34671983e-02, -7.52713121e-01,  1.97146602e-02, -6.64744905e-02,\n",
       "       -1.72854710e-01,  1.95780695e-01, -8.17535947e-02, -7.93460999e-02,\n",
       "        5.75907439e-02, -1.17578533e-02,  1.24481590e-01,  5.95893215e-03,\n",
       "       -5.14475457e-03, -3.57319447e-01, -2.75251614e-02,  9.15149752e-02,\n",
       "       -2.67241079e-05,  3.14513023e-03,  9.41660378e-03,  6.13422911e-04,\n",
       "        5.99748251e-04, -7.29486145e-02,  2.44495643e-01, -3.18860499e-03,\n",
       "       -5.94051361e-04,  2.61109537e-02,  1.43735071e-02, -2.90340203e-04,\n",
       "       -2.83037658e-03,  1.30944702e-04, -1.02165212e-02,  4.86026427e-02,\n",
       "        1.47653283e-01,  4.46085159e-01, -2.62434052e-01, -5.42786068e-04,\n",
       "        1.85141610e-01, -2.20724596e-03,  7.07167246e-04,  7.45274007e-02,\n",
       "       -1.29964786e-03, -1.01660139e-01, -1.25634658e-03,  3.65432202e-04,\n",
       "        2.26232882e-02,  3.11004206e-02, -3.68880624e-02, -9.41574870e-02,\n",
       "       -9.75506098e-02,  1.37900826e-01,  6.93533609e-02,  5.64672844e-02,\n",
       "        2.55857764e-02, -4.68660672e-02, -2.67311888e-01, -1.46318768e-01,\n",
       "       -3.27089711e-01,  2.30479816e-01,  4.33131550e-01, -2.19707493e-01,\n",
       "        4.64595997e-01, -3.91083525e-01,  5.35570817e-02,  1.51961007e-01,\n",
       "        1.54960226e-01, -9.39549420e-04,  1.92096549e-02,  4.21410651e-03,\n",
       "        3.04573577e-02,  1.76039727e-04,  7.49448470e-03,  1.65016251e-03,\n",
       "        3.20819850e-04, -1.67696491e-03,  1.01820208e-03,  2.78061749e-04,\n",
       "       -1.60696288e-01, -6.24112433e-02,  2.63205257e-03,  2.19292375e-01,\n",
       "       -1.38361840e-02,  9.69367722e-02,  1.87654320e-01, -3.10120102e-03,\n",
       "        1.60668957e-01, -1.09404303e-02, -3.19657787e-02,  6.05547285e-05,\n",
       "       -1.04652486e-02,  2.47904580e-05,  1.48453048e-03,  4.52371073e-02,\n",
       "       -2.11004287e-03, -1.10607428e-01,  4.79702832e-06,  4.47288138e-03,\n",
       "        4.01869045e-02,  4.23568689e-03,  1.93746514e-02, -6.67859932e-02,\n",
       "       -1.29295555e+00,  1.59534457e-02,  3.68601296e-01, -8.61889265e-02,\n",
       "        2.13621913e-02,  2.74878471e-01, -1.03866798e-02, -6.87716777e-02,\n",
       "        1.02172585e-03, -1.28356456e-02,  1.25296381e-02, -3.03416566e-01,\n",
       "       -1.20818782e-02, -1.24019948e-02, -2.15765458e-01, -3.63523436e-02,\n",
       "        2.26896910e-01,  1.96810529e-02, -9.87362987e-03, -5.66118587e-01,\n",
       "       -1.33435980e+00, -7.11864664e-02, -2.81354820e-02, -3.26213356e-01,\n",
       "       -2.90435841e-01,  3.84682138e-01,  2.80843279e-01, -6.78531630e-01,\n",
       "        1.10101744e-01, -1.43963023e-01, -4.47456131e-02,  1.07576726e-01,\n",
       "        7.44451240e-01, -6.50586046e-02,  1.22120924e-01,  7.08702417e-04,\n",
       "       -2.00679115e-02,  1.15989890e-01, -3.81060124e-03, -1.90657580e-02,\n",
       "        3.43779460e-03, -1.60792825e-03,  1.32105225e-01, -3.74644275e-02,\n",
       "       -3.13515311e-03, -5.81086453e-01,  1.52461045e-02,  3.60007216e-02,\n",
       "       -6.52031998e-01,  1.20803413e-01, -9.55888476e-02, -6.70765637e-02,\n",
       "       -4.02623466e-01, -1.63292650e-03, -4.78912543e-02,  1.06402855e-03,\n",
       "        6.95369282e-03,  8.71177227e-01, -4.85255595e-02, -1.73370824e-01,\n",
       "        1.27653613e-03,  4.18465313e-03,  4.06035074e-02, -4.42194553e-05,\n",
       "       -6.13428057e-04,  9.07857999e-04,  3.29549594e-03, -6.96682421e-04,\n",
       "        2.64046288e-03,  3.97004684e-02,  2.99271488e-04, -1.34470150e-02,\n",
       "       -5.90077096e-03, -9.79608026e-04, -2.14952247e-03, -5.26544699e-02,\n",
       "       -1.06835905e-03, -3.13633688e-03, -2.63348208e-01, -9.01856464e-03,\n",
       "       -1.68108623e-01, -4.82377977e-03, -9.65396132e-04,  3.30157849e-02,\n",
       "        4.25769091e-03, -3.08119165e-02, -1.87453217e-01,  2.85663447e-02,\n",
       "        2.17153778e-01,  1.93643922e-02, -1.02538098e-02,  2.65749544e-02,\n",
       "       -2.23830882e-01,  2.52200448e-02, -7.21794497e-02, -5.38228783e-03,\n",
       "        7.65004386e-02,  5.40562088e-04,  1.52500133e-02,  9.35956164e-02,\n",
       "        7.20948049e-03, -6.27564597e-02, -4.79247224e-02, -2.11765186e-02,\n",
       "       -1.11465403e-01,  3.90629346e-02,  9.39996053e-02,  6.31896462e-02,\n",
       "        5.14115239e-03,  1.53748751e-01, -3.52377711e-03, -2.13250841e-02,\n",
       "        1.03337687e-02, -1.24059825e-01, -1.95588517e-01, -2.61665276e-03,\n",
       "        2.72644697e-02, -9.21237356e-02,  9.27280018e-04, -2.35094798e-02,\n",
       "       -4.85439283e-01,  1.73277627e-02, -2.73622154e-02, -3.00111656e-01,\n",
       "        6.08013622e-03,  1.73057702e+00,  1.12881672e-01,  4.35060128e-01,\n",
       "       -5.74732389e-01,  2.90692597e-01,  2.23323528e-01, -7.86289068e-02,\n",
       "        3.88321687e-01,  1.11864218e-01, -1.10142916e+00,  1.25854553e-01,\n",
       "        3.87065549e+00, -3.73656914e-01,  7.78167083e-02, -1.90319729e-01,\n",
       "       -7.16042438e-02, -7.12891040e-02,  1.68764904e-02,  3.86946973e-02,\n",
       "       -4.60962890e-01,  1.16748339e-01, -1.55536432e-02,  5.15941020e-02,\n",
       "       -9.35609317e-02, -2.76981309e-01,  2.30167865e-01,  9.65293986e-02,\n",
       "       -2.73956644e-01,  3.40986460e-02, -6.16901744e-01, -2.02794768e-02,\n",
       "        5.93489397e-02, -3.72903259e-02,  4.33145883e-01,  4.28873740e-01,\n",
       "       -4.41260476e-03, -6.69424047e-02,  4.42187243e-02, -1.12151517e+00,\n",
       "       -1.02341105e-01,  4.54888794e-01, -1.75647899e-02,  4.04106059e-02,\n",
       "        2.75409623e+00, -4.74086935e-02, -6.12121517e-01,  1.07076833e-03,\n",
       "       -3.93197391e-01,  1.03816526e-01, -6.06079832e-03,  2.28284844e-02,\n",
       "        9.98348725e-03, -4.12529143e-02, -1.75520243e+00, -1.02834260e+00,\n",
       "        5.64303491e-02,  3.58944092e-01,  4.38690385e-02, -1.77649100e-01,\n",
       "        9.48118386e-01, -3.55892112e-02, -9.18794754e-01,  3.04467719e-03,\n",
       "        2.05525852e-01, -1.58532208e-03, -3.61681727e-02,  4.11096328e-03,\n",
       "       -1.84819248e-02,  8.97453120e-01, -1.81956810e-01,  5.42305082e-01,\n",
       "        6.26823708e-04,  2.20883874e-02, -8.84410047e-02,  9.45268992e-05,\n",
       "        6.05577300e-03,  7.01588303e-05, -9.61124016e-05, -1.71524154e-03,\n",
       "        2.87016973e-04,  1.45962487e-03,  5.62468631e-02,  9.31843774e-02,\n",
       "       -2.65343414e-03, -1.59898179e-02, -2.01755739e-03, -9.61513420e-03,\n",
       "        2.36063396e-02, -3.04219802e-03, -1.77461383e-01,  4.80600010e-03,\n",
       "        3.04243682e-04,  4.51249453e-05,  4.75560102e-03, -3.12720247e-04,\n",
       "        1.91908574e-05, -4.40306368e-02,  1.47312442e-03,  4.25370603e-06,\n",
       "        8.84485002e-06, -8.28093177e-04,  1.58094411e-03,  5.71703641e-01,\n",
       "        4.25115617e-01, -6.74184779e-03, -1.42637082e+00,  7.13667095e-02,\n",
       "        4.13067422e-02, -7.99227015e-01,  7.32169836e-02, -6.60219225e-01,\n",
       "       -1.17844712e-02,  7.38798650e-02, -1.69213232e-03,  1.24989543e-02,\n",
       "        8.74766560e-04,  5.52255590e-04,  2.33095907e-01, -3.35779158e-03,\n",
       "        7.91740734e-01,  3.79501784e-04, -3.43838886e-02, -3.79443949e-02,\n",
       "        1.46703199e+00, -8.19133693e-02,  1.64809300e-01, -1.68625416e-02,\n",
       "        2.77471134e-01, -2.04401030e-03, -2.58501751e-02,  3.64034910e-03,\n",
       "        1.91828932e-03,  1.76322600e+00, -1.11011364e-01, -2.30603700e-01,\n",
       "        1.16889723e-03, -5.15093467e-03,  5.36768039e-02,  3.72152203e-05,\n",
       "        1.43323921e-03, -1.84868934e-05, -1.08264042e-05, -4.80875672e-02,\n",
       "        3.64199468e-03,  6.56136901e-03, -1.12830719e-04, -1.59044684e-04,\n",
       "       -3.93095458e-03,  1.57384283e-01, -2.45533693e-02, -4.15837938e-01,\n",
       "        1.40359338e-03,  2.14128874e-02,  6.80798824e-02, -3.09014568e-06,\n",
       "       -4.06533682e-05, -1.28454043e-03, -1.11829618e-02])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_interaction_test = interaction.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model2.predict(features_interaction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.807654396164814"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1627098714574124"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28143.063127576184"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thus our model is badly performing on the features after applying PloynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let us try Ridge and Lasso Regressions after standardizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.1780e-02, 0.0000e+00, 4.0500e+00, 0.0000e+00, 5.1000e-01,\n",
       "       6.4160e+00, 8.4100e+01, 2.6463e+00, 5.0000e+00, 2.9600e+02,\n",
       "       1.6600e+01, 3.9550e+02, 9.0400e+00])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.406801  , -0.50512499, -1.02225586, -0.28154625, -0.40521827,\n",
       "        0.12577051,  0.55383118, -0.52734802, -0.51436915, -0.66777595,\n",
       "       -0.74457062,  0.41241246, -0.47605794])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_std[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we have standardized the features let us once try the LinearRegression and one with polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = regression.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204490.25723192788"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321.5754254923366"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#worse then our model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_interaction2 = interaction.fit_transform(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = regression.fit(features_interaction2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_interaction_test2 = interaction.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = model4.predict(features_interaction_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.692118233908456"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thus our model4 has worsen from model2 after standardizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = ridge.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.168235652913516"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.826702401972994"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1627098714574124"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.51744423117726"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thus it can be seen that the performance is not much improved above our Simple LinerRegressio, infact it is slightly bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = ridge.fit(features_interaction2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred6 = model6.predict(features_interaction_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.242844983945054"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.692118233908456"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#much better performance than the model4 but almost as same as or little less than model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = lasso.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred7 = model7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3959415858680737"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8 = lasso.fit(features_interaction2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred8 = model8.predict(features_interaction_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.662992946452553"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we have a model that performs better than the Simple Linear Regression Model.\n",
    "It is a Lasso Model whoes features have first been Standardized using StandardScaler and the PolynomialFeatures have been applied on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let us Quickly try the RandomForest and ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03882326, 0.00128965, 0.00666634, 0.00083441, 0.01126266,\n",
       "       0.43952034, 0.01677196, 0.06033768, 0.00463625, 0.01254026,\n",
       "       0.01723229, 0.01205809, 0.37802681])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred9 = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1326842105263157"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best Model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let us try ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354, 13)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\vijay\\anaconda4\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "ann.add(Dense(units=13,activation='relu',input_shape=(X_train.shape[1],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(Dense(units=13,activation='relu'))\n",
    "ann.add(Dense(units=7,activation='relu'))\n",
    "ann.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 354 samples\n",
      "Epoch 1/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 60.7397\n",
      "Epoch 2/100\n",
      "354/354 [==============================] - 0s 119us/sample - loss: 60.6655\n",
      "Epoch 3/100\n",
      "354/354 [==============================] - 0s 110us/sample - loss: 55.8875\n",
      "Epoch 4/100\n",
      "354/354 [==============================] - 0s 107us/sample - loss: 59.7405\n",
      "Epoch 5/100\n",
      "354/354 [==============================] - 0s 158us/sample - loss: 62.0135\n",
      "Epoch 6/100\n",
      "354/354 [==============================] - 0s 122us/sample - loss: 59.4987\n",
      "Epoch 7/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 54.3281\n",
      "Epoch 8/100\n",
      "354/354 [==============================] - 0s 147us/sample - loss: 59.8582\n",
      "Epoch 9/100\n",
      "354/354 [==============================] - 0s 150us/sample - loss: 59.0083\n",
      "Epoch 10/100\n",
      "354/354 [==============================] - 0s 141us/sample - loss: 57.5495\n",
      "Epoch 11/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 63.2884\n",
      "Epoch 12/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 55.0094\n",
      "Epoch 13/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 57.2617\n",
      "Epoch 14/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 53.1970\n",
      "Epoch 15/100\n",
      "354/354 [==============================] - 0s 124us/sample - loss: 57.2142\n",
      "Epoch 16/100\n",
      "354/354 [==============================] - 0s 127us/sample - loss: 56.6637\n",
      "Epoch 17/100\n",
      "354/354 [==============================] - 0s 122us/sample - loss: 53.3657\n",
      "Epoch 18/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 54.4328\n",
      "Epoch 19/100\n",
      "354/354 [==============================] - 0s 147us/sample - loss: 56.3729\n",
      "Epoch 20/100\n",
      "354/354 [==============================] - 0s 141us/sample - loss: 54.1034\n",
      "Epoch 21/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 56.3153\n",
      "Epoch 22/100\n",
      "354/354 [==============================] - 0s 124us/sample - loss: 57.1884\n",
      "Epoch 23/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 59.9548\n",
      "Epoch 24/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 50.5620\n",
      "Epoch 25/100\n",
      "354/354 [==============================] - 0s 141us/sample - loss: 54.1301\n",
      "Epoch 26/100\n",
      "354/354 [==============================] - 0s 141us/sample - loss: 54.3888\n",
      "Epoch 27/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 56.6460\n",
      "Epoch 28/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 50.8117\n",
      "Epoch 29/100\n",
      "354/354 [==============================] - 0s 144us/sample - loss: 49.7397\n",
      "Epoch 30/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 54.0804\n",
      "Epoch 31/100\n",
      "354/354 [==============================] - 0s 144us/sample - loss: 54.1421\n",
      "Epoch 32/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 52.1939\n",
      "Epoch 33/100\n",
      "354/354 [==============================] - 0s 144us/sample - loss: 56.6007\n",
      "Epoch 34/100\n",
      "354/354 [==============================] - 0s 122us/sample - loss: 50.2804\n",
      "Epoch 35/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 48.7199\n",
      "Epoch 36/100\n",
      "354/354 [==============================] - 0s 124us/sample - loss: 51.3179\n",
      "Epoch 37/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 50.5785\n",
      "Epoch 38/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 49.6736\n",
      "Epoch 39/100\n",
      "354/354 [==============================] - 0s 113us/sample - loss: 52.7403\n",
      "Epoch 40/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 50.4183\n",
      "Epoch 41/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 49.1742\n",
      "Epoch 42/100\n",
      "354/354 [==============================] - 0s 116us/sample - loss: 49.9294\n",
      "Epoch 43/100\n",
      "354/354 [==============================] - 0s 164us/sample - loss: 53.1735\n",
      "Epoch 44/100\n",
      "354/354 [==============================] - 0s 141us/sample - loss: 48.5352\n",
      "Epoch 45/100\n",
      "354/354 [==============================] - 0s 150us/sample - loss: 51.6022\n",
      "Epoch 46/100\n",
      "354/354 [==============================] - 0s 127us/sample - loss: 53.2374\n",
      "Epoch 47/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 55.9005\n",
      "Epoch 48/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 47.6561\n",
      "Epoch 49/100\n",
      "354/354 [==============================] - 0s 113us/sample - loss: 49.9930\n",
      "Epoch 50/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 45.9456\n",
      "Epoch 51/100\n",
      "354/354 [==============================] - 0s 150us/sample - loss: 46.7350\n",
      "Epoch 52/100\n",
      "354/354 [==============================] - 0s 138us/sample - loss: 60.0653\n",
      "Epoch 53/100\n",
      "354/354 [==============================] - 0s 141us/sample - loss: 45.1811\n",
      "Epoch 54/100\n",
      "354/354 [==============================] - 0s 144us/sample - loss: 50.9369\n",
      "Epoch 55/100\n",
      "354/354 [==============================] - 0s 113us/sample - loss: 50.7281\n",
      "Epoch 56/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 50.7521\n",
      "Epoch 57/100\n",
      "354/354 [==============================] - 0s 127us/sample - loss: 50.0969\n",
      "Epoch 58/100\n",
      "354/354 [==============================] - 0s 113us/sample - loss: 45.6675\n",
      "Epoch 59/100\n",
      "354/354 [==============================] - 0s 110us/sample - loss: 57.4614\n",
      "Epoch 60/100\n",
      "354/354 [==============================] - 0s 178us/sample - loss: 44.8957\n",
      "Epoch 61/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 59.0890\n",
      "Epoch 62/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 44.5130\n",
      "Epoch 63/100\n",
      "354/354 [==============================] - 0s 167us/sample - loss: 49.4799\n",
      "Epoch 64/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 43.6291\n",
      "Epoch 65/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 50.0024\n",
      "Epoch 66/100\n",
      "354/354 [==============================] - 0s 144us/sample - loss: 47.0367\n",
      "Epoch 67/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 45.1744\n",
      "Epoch 68/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 48.1055\n",
      "Epoch 69/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 45.5861\n",
      "Epoch 70/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 47.6834\n",
      "Epoch 71/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 49.0585\n",
      "Epoch 72/100\n",
      "354/354 [==============================] - 0s 127us/sample - loss: 44.9588\n",
      "Epoch 73/100\n",
      "354/354 [==============================] - 0s 141us/sample - loss: 49.0544\n",
      "Epoch 74/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 50.2282\n",
      "Epoch 75/100\n",
      "354/354 [==============================] - 0s 127us/sample - loss: 41.7544\n",
      "Epoch 76/100\n",
      "354/354 [==============================] - 0s 141us/sample - loss: 48.3046\n",
      "Epoch 77/100\n",
      "354/354 [==============================] - 0s 147us/sample - loss: 47.1145\n",
      "Epoch 78/100\n",
      "354/354 [==============================] - 0s 155us/sample - loss: 43.9019\n",
      "Epoch 79/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 46.4854\n",
      "Epoch 80/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 44.1190\n",
      "Epoch 81/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 46.1716\n",
      "Epoch 82/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 51.3450\n",
      "Epoch 83/100\n",
      "354/354 [==============================] - 0s 170us/sample - loss: 47.1539\n",
      "Epoch 84/100\n",
      "354/354 [==============================] - 0s 144us/sample - loss: 47.5634\n",
      "Epoch 85/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 42.9515\n",
      "Epoch 86/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 47.3358\n",
      "Epoch 87/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 44.5070\n",
      "Epoch 88/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 47.6782\n",
      "Epoch 89/100\n",
      "354/354 [==============================] - 0s 153us/sample - loss: 43.6470\n",
      "Epoch 90/100\n",
      "354/354 [==============================] - 0s 150us/sample - loss: 45.2162\n",
      "Epoch 91/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 41.7995\n",
      "Epoch 92/100\n",
      "354/354 [==============================] - 0s 139us/sample - loss: 45.1905\n",
      "Epoch 93/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 45.7506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "354/354 [==============================] - 0s 130us/sample - loss: 42.1611\n",
      "Epoch 95/100\n",
      "354/354 [==============================] - 0s 133us/sample - loss: 43.9558\n",
      "Epoch 96/100\n",
      "354/354 [==============================] - 0s 136us/sample - loss: 46.0213\n",
      "Epoch 97/100\n",
      "354/354 [==============================] - 0s 144us/sample - loss: 45.0513\n",
      "Epoch 98/100\n",
      "354/354 [==============================] - 0s 153us/sample - loss: 49.7044\n",
      "Epoch 99/100\n",
      "354/354 [==============================] - 0s 153us/sample - loss: 41.0364\n",
      "Epoch 100/100\n",
      "354/354 [==============================] - ETA: 0s - loss: 93.42 - 0s 158us/sample - loss: 46.7106\n"
     ]
    }
   ],
   "source": [
    "history = ann.fit(x=X_train,y=y_train,batch_size=32,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred10=ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.384065419435501"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.747606390599934"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,pred10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.51744423117726"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thus the mean absolute error is low the mean squared error is not less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Y_orig'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Y_predicted'] = pred10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 2)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Difference'] = df['Y_orig']-df['Y_predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_orig</th>\n",
       "      <th>Y_predicted</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>25.707367</td>\n",
       "      <td>-2.107367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>30.895470</td>\n",
       "      <td>1.504530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>18.842621</td>\n",
       "      <td>-5.242621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>22.793213</td>\n",
       "      <td>0.006787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.383385</td>\n",
       "      <td>-0.283385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>19.233704</td>\n",
       "      <td>0.766296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.8</td>\n",
       "      <td>18.475159</td>\n",
       "      <td>-0.675159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>12.911695</td>\n",
       "      <td>1.088305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.6</td>\n",
       "      <td>20.089058</td>\n",
       "      <td>-0.489058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.8</td>\n",
       "      <td>20.385441</td>\n",
       "      <td>-3.585441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.5</td>\n",
       "      <td>21.182346</td>\n",
       "      <td>0.317654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.9</td>\n",
       "      <td>19.180954</td>\n",
       "      <td>-0.280954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-11.829013</td>\n",
       "      <td>18.829013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.2</td>\n",
       "      <td>18.725254</td>\n",
       "      <td>2.474746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.5</td>\n",
       "      <td>22.613922</td>\n",
       "      <td>-4.113922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.8</td>\n",
       "      <td>17.238937</td>\n",
       "      <td>12.561063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.230167</td>\n",
       "      <td>-1.430167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.2</td>\n",
       "      <td>5.227571</td>\n",
       "      <td>4.972429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50.0</td>\n",
       "      <td>32.687305</td>\n",
       "      <td>17.312695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.1</td>\n",
       "      <td>16.181847</td>\n",
       "      <td>-2.081847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>25.2</td>\n",
       "      <td>26.084309</td>\n",
       "      <td>-0.884309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>29.1</td>\n",
       "      <td>27.419426</td>\n",
       "      <td>1.680574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12.7</td>\n",
       "      <td>13.917729</td>\n",
       "      <td>-1.217729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22.4</td>\n",
       "      <td>24.481827</td>\n",
       "      <td>-2.081827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14.2</td>\n",
       "      <td>15.940057</td>\n",
       "      <td>-1.740057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>13.8</td>\n",
       "      <td>14.763368</td>\n",
       "      <td>-0.963368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20.3</td>\n",
       "      <td>20.772522</td>\n",
       "      <td>-0.472522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>14.9</td>\n",
       "      <td>7.356874</td>\n",
       "      <td>7.543126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21.7</td>\n",
       "      <td>21.276367</td>\n",
       "      <td>0.423633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.3</td>\n",
       "      <td>19.943207</td>\n",
       "      <td>-1.643207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>23.1</td>\n",
       "      <td>22.231117</td>\n",
       "      <td>0.868883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>23.8</td>\n",
       "      <td>25.106243</td>\n",
       "      <td>-1.306243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.818214</td>\n",
       "      <td>-2.818214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20.8</td>\n",
       "      <td>22.197830</td>\n",
       "      <td>-1.397830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>19.1</td>\n",
       "      <td>12.513368</td>\n",
       "      <td>6.586632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>19.4</td>\n",
       "      <td>12.810971</td>\n",
       "      <td>6.589029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34.7</td>\n",
       "      <td>27.956982</td>\n",
       "      <td>6.743018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>19.5</td>\n",
       "      <td>24.067871</td>\n",
       "      <td>-4.567871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>24.4</td>\n",
       "      <td>20.360703</td>\n",
       "      <td>4.039297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>23.4</td>\n",
       "      <td>20.379532</td>\n",
       "      <td>3.020468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>19.7</td>\n",
       "      <td>15.461801</td>\n",
       "      <td>4.238199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>28.2</td>\n",
       "      <td>29.749981</td>\n",
       "      <td>-1.549981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>50.0</td>\n",
       "      <td>34.028107</td>\n",
       "      <td>15.971893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>17.4</td>\n",
       "      <td>19.836182</td>\n",
       "      <td>-2.436182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22.6</td>\n",
       "      <td>25.110882</td>\n",
       "      <td>-2.510882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15.1</td>\n",
       "      <td>16.962303</td>\n",
       "      <td>-1.862303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>13.1</td>\n",
       "      <td>16.694302</td>\n",
       "      <td>-3.594302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>24.2</td>\n",
       "      <td>21.477768</td>\n",
       "      <td>2.722232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>19.9</td>\n",
       "      <td>16.566338</td>\n",
       "      <td>3.333662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>24.0</td>\n",
       "      <td>28.379612</td>\n",
       "      <td>-4.379612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y_orig  Y_predicted  Difference\n",
       "0     23.6    25.707367   -2.107367\n",
       "1     32.4    30.895470    1.504530\n",
       "2     13.6    18.842621   -5.242621\n",
       "3     22.8    22.793213    0.006787\n",
       "4     16.1    16.383385   -0.283385\n",
       "5     20.0    19.233704    0.766296\n",
       "6     17.8    18.475159   -0.675159\n",
       "7     14.0    12.911695    1.088305\n",
       "8     19.6    20.089058   -0.489058\n",
       "9     16.8    20.385441   -3.585441\n",
       "10    21.5    21.182346    0.317654\n",
       "11    18.9    19.180954   -0.280954\n",
       "12     7.0   -11.829013   18.829013\n",
       "13    21.2    18.725254    2.474746\n",
       "14    18.5    22.613922   -4.113922\n",
       "15    29.8    17.238937   12.561063\n",
       "16    18.8    20.230167   -1.430167\n",
       "17    10.2     5.227571    4.972429\n",
       "18    50.0    32.687305   17.312695\n",
       "19    14.1    16.181847   -2.081847\n",
       "20    25.2    26.084309   -0.884309\n",
       "21    29.1    27.419426    1.680574\n",
       "22    12.7    13.917729   -1.217729\n",
       "23    22.4    24.481827   -2.081827\n",
       "24    14.2    15.940057   -1.740057\n",
       "25    13.8    14.763368   -0.963368\n",
       "26    20.3    20.772522   -0.472522\n",
       "27    14.9     7.356874    7.543126\n",
       "28    21.7    21.276367    0.423633\n",
       "29    18.3    19.943207   -1.643207\n",
       "30    23.1    22.231117    0.868883\n",
       "31    23.8    25.106243   -1.306243\n",
       "32    15.0    17.818214   -2.818214\n",
       "33    20.8    22.197830   -1.397830\n",
       "34    19.1    12.513368    6.586632\n",
       "35    19.4    12.810971    6.589029\n",
       "36    34.7    27.956982    6.743018\n",
       "37    19.5    24.067871   -4.567871\n",
       "38    24.4    20.360703    4.039297\n",
       "39    23.4    20.379532    3.020468\n",
       "40    19.7    15.461801    4.238199\n",
       "41    28.2    29.749981   -1.549981\n",
       "42    50.0    34.028107   15.971893\n",
       "43    17.4    19.836182   -2.436182\n",
       "44    22.6    25.110882   -2.510882\n",
       "45    15.1    16.962303   -1.862303\n",
       "46    13.1    16.694302   -3.594302\n",
       "47    24.2    21.477768    2.722232\n",
       "48    19.9    16.566338    3.333662\n",
       "49    24.0    28.379612   -4.379612"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_orig</th>\n",
       "      <th>Y_predicted</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>18.9</td>\n",
       "      <td>22.382153</td>\n",
       "      <td>-3.482153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>35.4</td>\n",
       "      <td>28.147057</td>\n",
       "      <td>7.252943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>15.2</td>\n",
       "      <td>19.274193</td>\n",
       "      <td>-4.074193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>26.5</td>\n",
       "      <td>24.503555</td>\n",
       "      <td>1.996445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>43.5</td>\n",
       "      <td>29.346458</td>\n",
       "      <td>14.153542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>21.2</td>\n",
       "      <td>16.453880</td>\n",
       "      <td>4.746120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>18.4</td>\n",
       "      <td>18.116890</td>\n",
       "      <td>0.283110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>28.5</td>\n",
       "      <td>32.552937</td>\n",
       "      <td>-4.052937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>23.9</td>\n",
       "      <td>24.032055</td>\n",
       "      <td>-0.132055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>18.5</td>\n",
       "      <td>17.998337</td>\n",
       "      <td>0.501663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>25.0</td>\n",
       "      <td>24.234016</td>\n",
       "      <td>0.765984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>35.4</td>\n",
       "      <td>31.588211</td>\n",
       "      <td>3.811789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>31.5</td>\n",
       "      <td>24.472183</td>\n",
       "      <td>7.027817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>20.2</td>\n",
       "      <td>12.722562</td>\n",
       "      <td>7.477438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>24.1</td>\n",
       "      <td>24.165833</td>\n",
       "      <td>-0.065833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>20.0</td>\n",
       "      <td>18.049854</td>\n",
       "      <td>1.950146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>13.1</td>\n",
       "      <td>16.941261</td>\n",
       "      <td>-3.841261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>24.8</td>\n",
       "      <td>26.100254</td>\n",
       "      <td>-1.300254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>30.8</td>\n",
       "      <td>30.996010</td>\n",
       "      <td>-0.196010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>12.7</td>\n",
       "      <td>6.892015</td>\n",
       "      <td>5.807985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.249718</td>\n",
       "      <td>-0.249718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>23.7</td>\n",
       "      <td>21.502037</td>\n",
       "      <td>2.197963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>10.8</td>\n",
       "      <td>7.001092</td>\n",
       "      <td>3.798908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>20.6</td>\n",
       "      <td>26.420479</td>\n",
       "      <td>-5.820479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>20.8</td>\n",
       "      <td>19.918083</td>\n",
       "      <td>0.881917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.567872</td>\n",
       "      <td>3.432128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>20.1</td>\n",
       "      <td>22.173103</td>\n",
       "      <td>-2.073103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>48.5</td>\n",
       "      <td>33.627411</td>\n",
       "      <td>14.872589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10.9</td>\n",
       "      <td>12.847566</td>\n",
       "      <td>-1.947566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7.0</td>\n",
       "      <td>13.086801</td>\n",
       "      <td>-6.086801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>20.9</td>\n",
       "      <td>22.478622</td>\n",
       "      <td>-1.578622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>17.2</td>\n",
       "      <td>8.043115</td>\n",
       "      <td>9.156885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>20.9</td>\n",
       "      <td>25.719345</td>\n",
       "      <td>-4.819345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>9.7</td>\n",
       "      <td>9.651727</td>\n",
       "      <td>0.048273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>19.4</td>\n",
       "      <td>23.824974</td>\n",
       "      <td>-4.424974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>29.0</td>\n",
       "      <td>23.331066</td>\n",
       "      <td>5.668934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>16.4</td>\n",
       "      <td>13.654527</td>\n",
       "      <td>2.745473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>25.0</td>\n",
       "      <td>25.144279</td>\n",
       "      <td>-0.144279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>25.0</td>\n",
       "      <td>26.385475</td>\n",
       "      <td>-1.385475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>17.1</td>\n",
       "      <td>19.765747</td>\n",
       "      <td>-2.665747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>23.2</td>\n",
       "      <td>22.743690</td>\n",
       "      <td>0.456310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>10.4</td>\n",
       "      <td>2.861772</td>\n",
       "      <td>7.538228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>19.6</td>\n",
       "      <td>21.246586</td>\n",
       "      <td>-1.646586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>17.2</td>\n",
       "      <td>17.186440</td>\n",
       "      <td>0.013560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>27.5</td>\n",
       "      <td>22.168839</td>\n",
       "      <td>5.331161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>23.0</td>\n",
       "      <td>21.180267</td>\n",
       "      <td>1.819733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>50.0</td>\n",
       "      <td>21.940445</td>\n",
       "      <td>28.059555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17.9</td>\n",
       "      <td>-9.390887</td>\n",
       "      <td>27.290887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.6</td>\n",
       "      <td>8.524476</td>\n",
       "      <td>1.075524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>17.2</td>\n",
       "      <td>6.356301</td>\n",
       "      <td>10.843699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y_orig  Y_predicted  Difference\n",
       "50    18.9    22.382153   -3.482153\n",
       "51    35.4    28.147057    7.252943\n",
       "52    15.2    19.274193   -4.074193\n",
       "53    26.5    24.503555    1.996445\n",
       "54    43.5    29.346458   14.153542\n",
       "55    21.2    16.453880    4.746120\n",
       "56    18.4    18.116890    0.283110\n",
       "57    28.5    32.552937   -4.052937\n",
       "58    23.9    24.032055   -0.132055\n",
       "59    18.5    17.998337    0.501663\n",
       "60    25.0    24.234016    0.765984\n",
       "61    35.4    31.588211    3.811789\n",
       "62    31.5    24.472183    7.027817\n",
       "63    20.2    12.722562    7.477438\n",
       "64    24.1    24.165833   -0.065833\n",
       "65    20.0    18.049854    1.950146\n",
       "66    13.1    16.941261   -3.841261\n",
       "67    24.8    26.100254   -1.300254\n",
       "68    30.8    30.996010   -0.196010\n",
       "69    12.7     6.892015    5.807985\n",
       "70    20.0    20.249718   -0.249718\n",
       "71    23.7    21.502037    2.197963\n",
       "72    10.8     7.001092    3.798908\n",
       "73    20.6    26.420479   -5.820479\n",
       "74    20.8    19.918083    0.881917\n",
       "75     5.0     1.567872    3.432128\n",
       "76    20.1    22.173103   -2.073103\n",
       "77    48.5    33.627411   14.872589\n",
       "78    10.9    12.847566   -1.947566\n",
       "79     7.0    13.086801   -6.086801\n",
       "80    20.9    22.478622   -1.578622\n",
       "81    17.2     8.043115    9.156885\n",
       "82    20.9    25.719345   -4.819345\n",
       "83     9.7     9.651727    0.048273\n",
       "84    19.4    23.824974   -4.424974\n",
       "85    29.0    23.331066    5.668934\n",
       "86    16.4    13.654527    2.745473\n",
       "87    25.0    25.144279   -0.144279\n",
       "88    25.0    26.385475   -1.385475\n",
       "89    17.1    19.765747   -2.665747\n",
       "90    23.2    22.743690    0.456310\n",
       "91    10.4     2.861772    7.538228\n",
       "92    19.6    21.246586   -1.646586\n",
       "93    17.2    17.186440    0.013560\n",
       "94    27.5    22.168839    5.331161\n",
       "95    23.0    21.180267    1.819733\n",
       "96    50.0    21.940445   28.059555\n",
       "97    17.9    -9.390887   27.290887\n",
       "98     9.6     8.524476    1.075524\n",
       "99    17.2     6.356301   10.843699"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_orig</th>\n",
       "      <th>Y_predicted</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>22.5</td>\n",
       "      <td>21.743916</td>\n",
       "      <td>0.756084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>21.4</td>\n",
       "      <td>20.376240</td>\n",
       "      <td>1.023760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8.560121</td>\n",
       "      <td>3.439879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>19.9</td>\n",
       "      <td>23.924397</td>\n",
       "      <td>-4.024397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>19.4</td>\n",
       "      <td>21.992100</td>\n",
       "      <td>-2.592100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>13.4</td>\n",
       "      <td>1.433587</td>\n",
       "      <td>11.966413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>18.2</td>\n",
       "      <td>22.528595</td>\n",
       "      <td>-4.328595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>24.6</td>\n",
       "      <td>24.173309</td>\n",
       "      <td>0.426691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21.1</td>\n",
       "      <td>24.494892</td>\n",
       "      <td>-3.394892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>24.7</td>\n",
       "      <td>29.605164</td>\n",
       "      <td>-4.905164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>8.7</td>\n",
       "      <td>-1.066474</td>\n",
       "      <td>9.766474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>27.5</td>\n",
       "      <td>14.143075</td>\n",
       "      <td>13.356925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>20.7</td>\n",
       "      <td>24.862801</td>\n",
       "      <td>-4.162801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>36.2</td>\n",
       "      <td>26.278095</td>\n",
       "      <td>9.921905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>31.6</td>\n",
       "      <td>25.180401</td>\n",
       "      <td>6.419599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>11.7</td>\n",
       "      <td>15.833741</td>\n",
       "      <td>-4.133741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>39.8</td>\n",
       "      <td>28.711449</td>\n",
       "      <td>11.088551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>13.9</td>\n",
       "      <td>12.996953</td>\n",
       "      <td>0.903047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>21.8</td>\n",
       "      <td>20.593239</td>\n",
       "      <td>1.206761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>23.7</td>\n",
       "      <td>24.069069</td>\n",
       "      <td>-0.369069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>17.6</td>\n",
       "      <td>20.855801</td>\n",
       "      <td>-3.255801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>24.4</td>\n",
       "      <td>24.161144</td>\n",
       "      <td>0.238856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>8.8</td>\n",
       "      <td>-0.237187</td>\n",
       "      <td>9.037187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>19.2</td>\n",
       "      <td>22.118336</td>\n",
       "      <td>-2.918336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>25.3</td>\n",
       "      <td>23.202469</td>\n",
       "      <td>2.097531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>20.4</td>\n",
       "      <td>24.529919</td>\n",
       "      <td>-4.129919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>23.1</td>\n",
       "      <td>27.906090</td>\n",
       "      <td>-4.806090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>37.9</td>\n",
       "      <td>30.340706</td>\n",
       "      <td>7.559294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>15.6</td>\n",
       "      <td>10.320294</td>\n",
       "      <td>5.279706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>45.4</td>\n",
       "      <td>29.938251</td>\n",
       "      <td>15.461749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>15.7</td>\n",
       "      <td>12.415719</td>\n",
       "      <td>3.284281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>22.6</td>\n",
       "      <td>19.169292</td>\n",
       "      <td>3.430708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>14.5</td>\n",
       "      <td>21.707207</td>\n",
       "      <td>-7.207207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>18.7</td>\n",
       "      <td>18.611088</td>\n",
       "      <td>0.088912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>17.8</td>\n",
       "      <td>7.802625</td>\n",
       "      <td>9.997375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.081276</td>\n",
       "      <td>-1.981276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>20.6</td>\n",
       "      <td>24.539696</td>\n",
       "      <td>-3.939696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>31.6</td>\n",
       "      <td>32.840179</td>\n",
       "      <td>-1.240179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>29.1</td>\n",
       "      <td>27.767933</td>\n",
       "      <td>1.332067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>15.6</td>\n",
       "      <td>20.649372</td>\n",
       "      <td>-5.049372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>17.5</td>\n",
       "      <td>20.552444</td>\n",
       "      <td>-3.052444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>22.5</td>\n",
       "      <td>25.533272</td>\n",
       "      <td>-3.033272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>19.4</td>\n",
       "      <td>26.086311</td>\n",
       "      <td>-6.686311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>19.3</td>\n",
       "      <td>16.859783</td>\n",
       "      <td>2.440217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>8.5</td>\n",
       "      <td>-0.292281</td>\n",
       "      <td>8.792281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>20.6</td>\n",
       "      <td>25.991375</td>\n",
       "      <td>-5.391375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>17.0</td>\n",
       "      <td>14.858842</td>\n",
       "      <td>2.141158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>17.1</td>\n",
       "      <td>14.603120</td>\n",
       "      <td>2.496880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>14.5</td>\n",
       "      <td>18.678093</td>\n",
       "      <td>-4.178093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>50.0</td>\n",
       "      <td>27.590973</td>\n",
       "      <td>22.409027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>14.3</td>\n",
       "      <td>14.999589</td>\n",
       "      <td>-0.699589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>12.6</td>\n",
       "      <td>16.830284</td>\n",
       "      <td>-4.230284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Y_orig  Y_predicted  Difference\n",
       "100    22.5    21.743916    0.756084\n",
       "101    21.4    20.376240    1.023760\n",
       "102    12.0     8.560121    3.439879\n",
       "103    19.9    23.924397   -4.024397\n",
       "104    19.4    21.992100   -2.592100\n",
       "105    13.4     1.433587   11.966413\n",
       "106    18.2    22.528595   -4.328595\n",
       "107    24.6    24.173309    0.426691\n",
       "108    21.1    24.494892   -3.394892\n",
       "109    24.7    29.605164   -4.905164\n",
       "110     8.7    -1.066474    9.766474\n",
       "111    27.5    14.143075   13.356925\n",
       "112    20.7    24.862801   -4.162801\n",
       "113    36.2    26.278095    9.921905\n",
       "114    31.6    25.180401    6.419599\n",
       "115    11.7    15.833741   -4.133741\n",
       "116    39.8    28.711449   11.088551\n",
       "117    13.9    12.996953    0.903047\n",
       "118    21.8    20.593239    1.206761\n",
       "119    23.7    24.069069   -0.369069\n",
       "120    17.6    20.855801   -3.255801\n",
       "121    24.4    24.161144    0.238856\n",
       "122     8.8    -0.237187    9.037187\n",
       "123    19.2    22.118336   -2.918336\n",
       "124    25.3    23.202469    2.097531\n",
       "125    20.4    24.529919   -4.129919\n",
       "126    23.1    27.906090   -4.806090\n",
       "127    37.9    30.340706    7.559294\n",
       "128    15.6    10.320294    5.279706\n",
       "129    45.4    29.938251   15.461749\n",
       "130    15.7    12.415719    3.284281\n",
       "131    22.6    19.169292    3.430708\n",
       "132    14.5    21.707207   -7.207207\n",
       "133    18.7    18.611088    0.088912\n",
       "134    17.8     7.802625    9.997375\n",
       "135    16.1    18.081276   -1.981276\n",
       "136    20.6    24.539696   -3.939696\n",
       "137    31.6    32.840179   -1.240179\n",
       "138    29.1    27.767933    1.332067\n",
       "139    15.6    20.649372   -5.049372\n",
       "140    17.5    20.552444   -3.052444\n",
       "141    22.5    25.533272   -3.033272\n",
       "142    19.4    26.086311   -6.686311\n",
       "143    19.3    16.859783    2.440217\n",
       "144     8.5    -0.292281    8.792281\n",
       "145    20.6    25.991375   -5.391375\n",
       "146    17.0    14.858842    2.141158\n",
       "147    17.1    14.603120    2.496880\n",
       "148    14.5    18.678093   -4.178093\n",
       "149    50.0    27.590973   22.409027\n",
       "150    14.3    14.999589   -0.699589\n",
       "151    12.6    16.830284   -4.230284"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thus it can be seen that the deviation is less for most of the records , however the output varies a lot for extreme samples , like for y = 50 or y<17 , thus the MAE is low but the MSE is high beacuse of these few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
